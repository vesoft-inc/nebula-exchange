# Use the command to submit the exchange job:

# spark-submit \
# --master "spark://master_ip:7077" \
# --driver-memory=2G --executor-memory=30G  \
# --num-executors=3 --total-executor-cores=60 \
# --class com.vesoft.nebula.exchange.Exchange \
# nebula-exchange_spark_2.4-3.0-SNAPSHOT.jar -c parquet.conf

{
  # Spark config
  spark: {
    app: {
      name: NebulaGraph Exchange
    }
  }

  # Nebula Graph config
  nebula: {
    address:{
      graph: ["127.0.0.1:9669","127.0.0.2:9669"]
      # if your NebulaGraph server is in virtual network like k8s, please config the leader address of meta.
      # use `SHOW meta leader` to see your meta leader's address
      meta: ["127.0.0.1:9559"]
    }
    user: root
    pswd: nebula
    space: test

    # nebula client connection parameters
    connection {
      # socket connect & execute timeout, unit: millisecond
      timeout: 30000
    }

    error: {
      # max number of failures, if the number of failures is bigger than max, then exit the application.
      max: 32
      # failed data will be recorded in output path, format with ngql
      output: "hdfs://127.0.0.1:9000/tmp/errors"
    }

    # use google's RateLimiter to limit the requests send to NebulaGraph
    rate: {
      # the stable throughput of RateLimiter
      limit: 1024
      # Acquires a permit from RateLimiter, unit: MILLISECONDS
      # if it can't be obtained within the specified timeout, then give up the request.
      timeout: 1000
    }
  }

  # Processing tags
  tags: [
    {
      name: tag-name
      type: {
        source: orc
        sink: client
      }
      # if your file in not in hdfs, config "file:///path/test.orc"
      path: "hdfs://ip:port/path/test.orc"
      fields: [orc-field-1, orc-field-2, orc-field-3]
      nebula.fields: [nebula-field-1, nebula-field-2, nebula-field-3]
      vertex: {
        field: orc-field-0
      }
      batch: 2000
      partition: 60
    }
  ]

  # process edges
  edges: [
    {
      name: edge-name
      type: {
        source: orc
        sink: client
      }
      path: "hdfs://ip:port/path/test.orc"
      fields: [orc-field-2, orc-field-3, orc-field-4]
      nebula.fields: [nebula-field-1, nebula-field-2, nebula-field-3]
      source: {
        field: orc-field-0
      }
      target: {
        field: orc-field-1
      }
        #ranking: orc-field-2
        batch: 2000
        partition: 60
      }
  ]
}
