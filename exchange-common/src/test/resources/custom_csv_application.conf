{
  # Spark 相关配置
  spark: {
    app: {
      name: NebulaGraph Exchange 3.8.0
    }
    driver: {
      cores: 1
      maxResultSize: 1G
    }
    executor: {
        memory:1G
    }

    cores: {
      max: 16
    }
  }

  # NebulaGraph 相关配置
  nebula: {
    address:{
      graph:["host.docker.internal:9669"]
      meta:["host.docker.internal:9559"]
    }

    # 指定拥有 NebulaGraph 写权限的用户名和密码。
    user: root
    pswd: 123456
    space: basketballplayer
    connection: {
      timeout: 3000
      retry: 3
    }
    execution: {
      retry: 3
    }
    error: {
      max: 32
      output: /tmp/errors
    }
    rate: {
      limit: 1024
      timeout: 1000
    }
  }

  # 处理点
  tags: [
    # 设置 Tag player 相关信息。
    {
      # 指定 NebulaGraph 中定义的 Tag 名称。
      name: player
      type: {
        # 指定数据源，使用 CSV。
        #source:csv
        source: custom
        # 指定如何将点数据导入 NebulaGraph ：Client 或 SST。
        sink: client
      }

      configResolver: com.vesoft.nebula.exchange.plugin.fileBase.ConfigResolverImpl
      path: "file:///opt/spark/data/vertex_player.csv"

      fields: [_c1, _c2]

      nebula.fields: [age, name]

      vertex: {
        field:_c0
      }
      # CUSTOM字段配置
      custom: {
        reader: com.vesoft.nebula.exchange.plugin.fileBase.CustomReaderImpl
        separator: ","
        header: false
      }

      # 指定单批次写入 NebulaGraph 的最大点数量。
      batch: 256

      # 数据写入 NebulaGraph 时需要创建的分区数。
      partition: 32
    }

    # 设置 Tag team 相关信息。
    {
      name: team
      type: {
        source: csv
        sink: client
      }
      #path: "hdfs://192.168.*.*:9000/data/vertex_team.csv"
      path: "file:///opt/spark/data/vertex_team.csv"
      fields: [_c1]
      nebula.fields: [name]
      vertex: {
        field:_c0
      }
      separator: ","
      header: false
      batch: 256
      partition: 32
    }
    # 如果需要添加更多点，请参考前面的配置进行添加。
  ]
  # 处理边
  edges: [
    # 设置 Edge type follow 相关信息。
    {
      # 指定 NebulaGraph 中定义的 Edge type 名称。
      name: follow
      type: {
        source: csv
        sink: client
      }

      path: "file:///opt/spark/data/edge_follow.csv"

      fields: [_c2]

      nebula.fields: [degree]

      source: {
        field: _c0
      }
      target: {
        field: _c1
      }

      # 指定的分隔符。默认值为英文逗号（,）。
      separator: ","

      header: false

      batch: 256

      # 数据写入 NebulaGraph 时需要创建的分区数。
      partition: 32
    }

    # 设置 Edge type serve 相关信息。
    {
      name: serve
      type: {
        source: csv
        sink: client
      }
      #path: "hdfs://192.168.*.*:9000/data/edge_serve.csv"
      path: "file:///opt/spark/data/edge_serve.csv"
      fields: [_c2,_c3]
      nebula.fields: [start_year, end_year]
      source: {
        field: _c0
      }
      target: {
        field: _c1
      }
      separator: ","
      header: false
      batch: 256
      partition: 32
    }

  ]
}